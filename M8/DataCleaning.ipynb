{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DataCleaning.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rdkVDYwSQCFy"
      },
      "source": [
        "Submit your Python file (.py) or share colab link (.ipynb). Be sure to comment your file well, and if needed, submit a Word document for additional comments. Ensure that at the top of your Python file and report you include:\n",
        "\n",
        "  1. Name of activity\n",
        "  2. Your name\n",
        "  3. Your UVA computing ID"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uhuVEHPWQKgj"
      },
      "source": [
        "This dataset consists of TV shows and movies available on Netflix as of 2019. The dataset is collected from Flixable which is a third-party Netflix search engine.\n",
        "\n",
        "In this assignment, you need to process this data set. And complete the following tasks if possible:\n",
        "\n",
        "How many duplicate records are there? Please delete all duplicate records?\n",
        "The percentage of missing data in each column.\n",
        "Extract date information from the 'date_added' column, and add 'date_added_year',''date_added_month', and 'date_added_day' columns.\n",
        "It is also crucial to have the dataset follow specific standards to fit a model. We need to explore the data in different ways to find out the inconsistent data. Much of the time, it depends on observations and experience. There is no set code to run and fix them all. In the ‘duration’ column, we cover two inconsistent data types -- the unit of some records is “min” and some other records is “Season”. Please separate the two types of records."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4Iw1LcMP2I6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRXz-pJwP2xr"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3XxG8r0UP3Y2"
      },
      "source": [
        "# df['timestamp_dt'] = pd.to_datetime(df['timestamp'], format='%Y-%m-%d')\n",
        "# df['year'] = df['timestamp_dt'].dt.year\n",
        "# df['month'] = df['timestamp_dt'].dt.month\n",
        "# df['weekday'] = df['timestamp_dt'].dt.weekday"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vORuUEiiP2uZ"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1_9P2kdQbNP"
      },
      "source": [
        "data['address_std'] = data['address'].str.lower()\n",
        "# remove leading and trailing whitespace.\n",
        "data['address_std'] = data['address_std'].str.strip()\n",
        "# remove period.\n",
        "data['address_std'] = data['address_std'].str.replace('\\\\.', '') \n",
        "# replace street with st.\n",
        "data['address_std'] = data['address_std'].str.replace('\\\\bstreet\\\\b', 'st')\n",
        "# replace apartment with apt.\n",
        "data['address_std'] = data['address_std'].str.replace('\\\\bapartment\\\\b', 'apt')\n",
        "# replace av with ave.\n",
        "data['address_std'] = data['address_std'].str.replace('\\\\bav\\\\b', 'ave')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GF7Yh72tP2rX"
      },
      "source": [
        ""
      ]
    }
  ]
}